{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries Used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-16T15:03:42.551024Z",
     "start_time": "2020-04-16T15:03:42.529909Z"
    }
   },
   "outputs": [],
   "source": [
    "from ftplib import FTP\n",
    "import string\n",
    "import os\n",
    "import time\n",
    "import math\n",
    "\n",
    "import pprint\n",
    "# prints the formatted representation of PrettyPrinter object\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "\n",
    "import boto3\n",
    "# Get the service client \n",
    "client = boto3.client('s3')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting FTP Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-16T15:05:55.345576Z",
     "start_time": "2020-04-16T15:03:43.674601Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "TimeoutError",
     "evalue": "[Errno 110] Connection timed out",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTimeoutError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-797f5e47eb31>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Domain name or server ip:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mftp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFTP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ec2-52-66-211-38.ap-south-1.compute.amazonaws.com'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mftp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'test_user'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpasswd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'rishabh'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/ftplib.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, host, user, passwd, acct, timeout, source_address)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhost\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0muser\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpasswd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macct\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/ftplib.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self, host, port, timeout, source_address)\u001b[0m\n\u001b[1;32m    150\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msource_address\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msource_address\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         self.sock = socket.create_connection((self.host, self.port), self.timeout,\n\u001b[0;32m--> 152\u001b[0;31m                                              source_address=self.source_address)\n\u001b[0m\u001b[1;32m    153\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfamily\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakefile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/socket.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address)\u001b[0m\n\u001b[1;32m    726\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0merr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    729\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m             \u001b[0;31m# Break explicitly a reference cycle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/socket.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address)\u001b[0m\n\u001b[1;32m    714\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0msource_address\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m                 \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_address\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msa\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m             \u001b[0;31m# Break explicitly a reference cycle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTimeoutError\u001b[0m: [Errno 110] Connection timed out"
     ]
    }
   ],
   "source": [
    "# from ftplib import FTP\n",
    "\n",
    "# Domain name or server ip:\n",
    "ftp = FTP('ec2-52-66-211-38.ap-south-1.compute.amazonaws.com')\n",
    "    \n",
    "ftp.login(user='test_user', passwd = 'rishabh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get all the file names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-16T14:13:22.962764Z",
     "start_time": "2020-04-16T14:11:11.883Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set the current directory on the server\n",
    "ftp.cwd('/files/ftp')\n",
    "\n",
    "# Return a list of file names\n",
    "ftp_files = ftp.nlst()\n",
    "\n",
    "# Printing\n",
    "pp.pprint(ftp_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get only CSV files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-15T15:15:10.046925Z",
     "start_time": "2020-04-15T15:15:10.025481Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   '9G9VYW23CU.csv',\n",
      "    'D029LRLIRA.csv',\n",
      "    'DN7A49XY69.csv',\n",
      "    'EDTMQD3VFB.csv',\n",
      "    'GJNZEL7QS7.csv',\n",
      "    'Measurement_info.csv',\n",
      "    'Measurement_summary.csv',\n",
      "    'N84NQPAZ5A.csv',\n",
      "    'SG75B3AMDD.csv',\n",
      "    'WMM6GGSTIQ.csv']\n"
     ]
    }
   ],
   "source": [
    "def filter_names(n) :\n",
    "    if n.endswith('csv') :\n",
    "        return True\n",
    "    else :\n",
    "        return False\n",
    "\n",
    "ftp_files = list(filter( filter_names, ftp_files ))\n",
    "\n",
    "# Printing\n",
    "pp.pprint(ftp_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Files which are already present in S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-15T15:15:10.509708Z",
     "start_time": "2020-04-15T15:15:10.051860Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   'Contents': [   {   'ETag': '\"a0ad38f3a09a0d0d0c2dd905736e6986\"',\n",
      "                        'Key': '9G9VYW23CU.csv',\n",
      "                        'LastModified': datetime.datetime(2020, 4, 15, 11, 49, 13, tzinfo=tzutc()),\n",
      "                        'Size': 354,\n",
      "                        'StorageClass': 'STANDARD'},\n",
      "                    {   'ETag': '\"571d1690191e982850f6e593049ff428\"',\n",
      "                        'Key': 'D029LRLIRA.csv',\n",
      "                        'LastModified': datetime.datetime(2020, 4, 15, 11, 49, 13, tzinfo=tzutc()),\n",
      "                        'Size': 341,\n",
      "                        'StorageClass': 'STANDARD'},\n",
      "                    {   'ETag': '\"8d2a79db85621494aa0c00583b0058cc\"',\n",
      "                        'Key': 'DN7A49XY69.csv',\n",
      "                        'LastModified': datetime.datetime(2020, 4, 15, 11, 49, 14, tzinfo=tzutc()),\n",
      "                        'Size': 467,\n",
      "                        'StorageClass': 'STANDARD'},\n",
      "                    {   'ETag': '\"f903d3cf0c7f126fa9f939c3e07ee66d\"',\n",
      "                        'Key': 'EDTMQD3VFB.csv',\n",
      "                        'LastModified': datetime.datetime(2020, 4, 15, 11, 49, 14, tzinfo=tzutc()),\n",
      "                        'Size': 237,\n",
      "                        'StorageClass': 'STANDARD'},\n",
      "                    {   'ETag': '\"a17ae887587039441d68f8d3ea1eeeb6\"',\n",
      "                        'Key': 'GJNZEL7QS7.csv',\n",
      "                        'LastModified': datetime.datetime(2020, 4, 15, 11, 49, 14, tzinfo=tzutc()),\n",
      "                        'Size': 316,\n",
      "                        'StorageClass': 'STANDARD'},\n",
      "                    {   'ETag': '\"a111385963ba51827e8a407dcac1e867\"',\n",
      "                        'Key': 'MOCK_DATA.json',\n",
      "                        'LastModified': datetime.datetime(2020, 4, 15, 11, 47, 45, tzinfo=tzutc()),\n",
      "                        'Size': 287,\n",
      "                        'StorageClass': 'STANDARD'},\n",
      "                    {   'ETag': '\"473ceb460162431ab988c08eabd8577f\"',\n",
      "                        'Key': 'N84NQPAZ5A.csv',\n",
      "                        'LastModified': datetime.datetime(2020, 4, 15, 11, 49, 14, tzinfo=tzutc()),\n",
      "                        'Size': 429,\n",
      "                        'StorageClass': 'STANDARD'},\n",
      "                    {   'ETag': '\"90782d0821d06338747f7927e53e3d00\"',\n",
      "                        'Key': 'SG75B3AMDD.csv',\n",
      "                        'LastModified': datetime.datetime(2020, 4, 15, 11, 49, 15, tzinfo=tzutc()),\n",
      "                        'Size': 387,\n",
      "                        'StorageClass': 'STANDARD'},\n",
      "                    {   'ETag': '\"fb05fa19d0981b560475a6753d3b3faa\"',\n",
      "                        'Key': 'WMM6GGSTIQ.csv',\n",
      "                        'LastModified': datetime.datetime(2020, 4, 15, 11, 49, 15, tzinfo=tzutc()),\n",
      "                        'Size': 277,\n",
      "                        'StorageClass': 'STANDARD'},\n",
      "                    {   'ETag': '\"d3ee934d3c9219a2f5a9230551cbf182\"',\n",
      "                        'Key': 'file.txt',\n",
      "                        'LastModified': datetime.datetime(2020, 4, 15, 11, 47, 45, tzinfo=tzutc()),\n",
      "                        'Size': 319,\n",
      "                        'StorageClass': 'STANDARD'},\n",
      "                    {   'ETag': '\"9bcac1874c0a07eef4be75ea99e2272e\"',\n",
      "                        'Key': 'people.json',\n",
      "                        'LastModified': datetime.datetime(2020, 4, 15, 11, 47, 47, tzinfo=tzutc()),\n",
      "                        'Size': 1612897,\n",
      "                        'StorageClass': 'STANDARD'}],\n",
      "    'EncodingType': 'url',\n",
      "    'IsTruncated': False,\n",
      "    'KeyCount': 11,\n",
      "    'MaxKeys': 1000,\n",
      "    'Name': 'rishabhsengar2611',\n",
      "    'Prefix': '',\n",
      "    'ResponseMetadata': {   'HTTPHeaders': {   'content-type': 'application/xml',\n",
      "                                               'date': 'Wed, 15 Apr 2020 '\n",
      "                                                       '15:15:11 GMT',\n",
      "                                               'server': 'AmazonS3',\n",
      "                                               'transfer-encoding': 'chunked',\n",
      "                                               'x-amz-bucket-region': 'ap-south-1',\n",
      "                                               'x-amz-id-2': 'BI8nFJsV/3fkfNgY4gOEo+qHYDrQdPgXEycDcDahgE7ArLLJsUk9wdWAH332Jum2eR30t/yoFK4=',\n",
      "                                               'x-amz-request-id': '7014ED663056D2BA'},\n",
      "                            'HTTPStatusCode': 200,\n",
      "                            'HostId': 'BI8nFJsV/3fkfNgY4gOEo+qHYDrQdPgXEycDcDahgE7ArLLJsUk9wdWAH332Jum2eR30t/yoFK4=',\n",
      "                            'RequestId': '7014ED663056D2BA',\n",
      "                            'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "try :\n",
    "    # Returns some or all of the objects in a bucket\n",
    "    s3_files = client.list_objects_v2(Bucket = 'rishabhsengar2611')\n",
    "except :\n",
    "    # if wrong bucket name is entered\n",
    "    print(\"No such Bucket \\n\")\n",
    "\n",
    "pp.pprint(s3_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-15T15:15:10.521768Z",
     "start_time": "2020-04-15T15:15:10.514445Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'9G9VYW23CU.csv'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dictionary Access to get the name of the first file\n",
    "s3_files['Contents'][0]['Key']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-15T15:15:10.535124Z",
     "start_time": "2020-04-15T15:15:10.526529Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "354"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dictionary Access to get the size of the first file\n",
    "s3_files['Contents'][0]['Size']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get S3 file names and there size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-15T15:15:10.559219Z",
     "start_time": "2020-04-15T15:15:10.542839Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Name \t\t Size\n",
      "\n",
      "9G9VYW23CU.csv\t\t354\n",
      "D029LRLIRA.csv\t\t341\n",
      "DN7A49XY69.csv\t\t467\n",
      "EDTMQD3VFB.csv\t\t237\n",
      "GJNZEL7QS7.csv\t\t316\n",
      "MOCK_DATA.json\t\t287\n",
      "N84NQPAZ5A.csv\t\t429\n",
      "SG75B3AMDD.csv\t\t387\n",
      "WMM6GGSTIQ.csv\t\t277\n",
      "file.txt\t\t319\n",
      "people.json\t\t1612897\n"
     ]
    }
   ],
   "source": [
    "# Used to store the s3 files names\n",
    "s3_files_names = []\n",
    "\n",
    "# Used to store the sizes of files\n",
    "s3_files_size = []\n",
    "\n",
    "print(\"File Name \\t\\t Size\\n\")\n",
    "# Print the files\n",
    "try :\n",
    "    for i in range( 0,len(s3_files['Contents']) ) :\n",
    "        s3_files_names.append(s3_files['Contents'][i]['Key'])\n",
    "        print(s3_files['Contents'][i]['Key'], end='\\t\\t')\n",
    "        s3_files_size.append(s3_files['Contents'][i]['Size'])\n",
    "        print(s3_files['Contents'][i]['Size'], end='\\n')\n",
    "        \n",
    "except KeyError :\n",
    "    print(\"Bucket is Empty\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove already present file in the s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-15T15:15:10.581135Z",
     "start_time": "2020-04-15T15:15:10.563067Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " To be Added\n",
      "['Measurement_info.csv', 'Measurement_summary.csv']\n",
      "\n",
      " Already Present\n",
      "[   '9G9VYW23CU.csv',\n",
      "    'D029LRLIRA.csv',\n",
      "    'DN7A49XY69.csv',\n",
      "    'EDTMQD3VFB.csv',\n",
      "    'GJNZEL7QS7.csv',\n",
      "    'N84NQPAZ5A.csv',\n",
      "    'SG75B3AMDD.csv',\n",
      "    'WMM6GGSTIQ.csv']\n"
     ]
    }
   ],
   "source": [
    "# Already present files\n",
    "s3_files_present = []\n",
    "\n",
    "def filter_names(n) :\n",
    "    if n in s3_files_names :\n",
    "        s3_files_present.append(n)\n",
    "        return False\n",
    "    else :\n",
    "        return True\n",
    "\n",
    "ftp_files = list(filter( filter_names, ftp_files ))\n",
    "\n",
    "\n",
    "print(\" To be Added\")\n",
    "pp.pprint(ftp_files)\n",
    "print(\"\\n Already Present\")\n",
    "pp.pprint(s3_files_present)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-15T15:15:10.683671Z",
     "start_time": "2020-04-15T15:15:10.584224Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Measurement_info.csv': 124452984, 'Measurement_summary.csv': 94076158}\n"
     ]
    }
   ],
   "source": [
    "# Make the Dictionary of filename and Size of the files present in FTP \n",
    "ftp_size = {}\n",
    "for i in ftp_files :\n",
    "# FTP.size(filename) ---- >Request the size of the file named filename on the server.\n",
    "    ftp_size[i] = ftp.size(i)\n",
    "\n",
    "pp.pprint(ftp_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding files to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-15T15:15:10.689188Z",
     "start_time": "2020-04-15T15:15:10.685596Z"
    }
   },
   "outputs": [],
   "source": [
    "# Each part must be at least 5 MB in size\n",
    "# Since AWS won't allow us to have size less than 5MB\n",
    "# 1024*1024*6 == 6MB\n",
    "chunk_size = 6291456"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-15T15:15:10.697992Z",
     "start_time": "2020-04-15T15:15:10.691040Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Measurement_info.csv\t\t124452984\n",
      "Measurement_summary.csv\t\t94076158\n"
     ]
    }
   ],
   "source": [
    "# ftp.size(ftp_files[0])\n",
    "for file in ftp_size :\n",
    "    print(file+\"\\t\\t\"+str(ftp_size[file]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Files which have size less than 6MB uploaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-15T15:15:10.706545Z",
     "start_time": "2020-04-15T15:15:10.699972Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "big files :  Measurement_info.csv  -->  size :  124452984\n",
      "big files :  Measurement_summary.csv  -->  size :  94076158\n"
     ]
    }
   ],
   "source": [
    "# Used to store the large files\n",
    "big_files = []\n",
    "\n",
    "# This for loop is used to upload files\n",
    "for file in ftp_size :\n",
    "    if ftp_size[file] < chunk_size :\n",
    "        \n",
    "        # Change the location\n",
    "        local_file = os.path.join('/home/bluepi/Desktop/',file)\n",
    "        \n",
    "        # Retrieve a file in binary transfer mode\n",
    "        # RETR command --> A RETR request asks the server to send the contents of a file \n",
    "        #                       over the data connection already established by the client.\n",
    "        ftp.retrbinary('RETR ' + file, open(local_file, 'wb').write)\n",
    "        print(\"retieved file :\\t\" + file,end='\\n' )\n",
    "        \n",
    "        # Upload file in binary mode in s3 object\n",
    "        # Useful when we perform multipsrt upload\n",
    "        with open(local_file, 'rb') as data:\n",
    "            client.upload_fileobj(Fileobj=data, Bucket= 'rishabhsengar2611', Key= file)\n",
    "            \n",
    "        print(\"uploaded file :\\t\" + file,end='\\n')\n",
    "        #os.remove(file)\n",
    "    else :\n",
    "        big_files.append(file)\n",
    "        print(\"big files :  \"+file+\"  -->  size :  \"+str(ftp_size[file]),end = '\\n')\n",
    "        \n",
    "# Errors :-\n",
    "# Brokenpipeerror errno 32\n",
    "# ftplib.error_perm: 530 Login authentication failed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Files to be uploaded in chunks( Working on it )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-15T15:15:10.822390Z",
     "start_time": "2020-04-15T15:15:10.745323Z"
    }
   },
   "outputs": [],
   "source": [
    "chunk_count = math.ceil(ftp_size[big_files[0]] / chunk_size)\n",
    "multipart_upload =client.create_multipart_upload(Bucket = 'rishabhsengar2611',Key = 'Measurement_summary.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-15T15:15:10.835288Z",
     "start_time": "2020-04-15T15:15:10.827224Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "print(type(multipart_upload['UploadId']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-15T15:15:10.843792Z",
     "start_time": "2020-04-15T15:15:10.838699Z"
    }
   },
   "outputs": [],
   "source": [
    "# response = client.upload_part(\n",
    "#     Body=file,\n",
    "#     Bucket='rishabhsengar2611',\n",
    "#     Key='Measurement_summary.csv',\n",
    "#     PartNumber='1',\n",
    "#     UploadId=multipart_upload['UploadId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-15T15:16:21.660281Z",
     "start_time": "2020-04-15T15:15:16.034339Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening local file Measurement_summary.csv\n",
      "Getting Measurement_summary.csv\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-053e1f80d72f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;31m# RETR is an FTP command\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Getting '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbig_files\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0mftp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrbinary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RETR '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbig_files\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhandleDownload\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/ftplib.py\u001b[0m in \u001b[0;36mretrbinary\u001b[0;34m(self, cmd, callback, blocksize, rest)\u001b[0m\n\u001b[1;32m    442\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransfercmd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 444\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblocksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    445\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# This will handle the data being downloaded\n",
    "# It will be explained shortly\n",
    "i=0\n",
    "j=0\n",
    "l = []\n",
    "def custom_callback(block):\n",
    "    global i,j\n",
    "    global l\n",
    "    if len(l) < chunk_size :\n",
    "        file.write(block)\n",
    "        l.append(block)\n",
    "        #print(os.stat('Measurement_summary.csv').st_size,end='\\t')\n",
    "    else :\n",
    "        print(\"Uploading----\")\n",
    "        \n",
    "        response = client.upload_part(\n",
    "        Body=b'l',\n",
    "        Bucket='rishabhsengar2611',\n",
    "        Key='Measurement_summary.csv',\n",
    "        PartNumber=i+1,\n",
    "        UploadId=multipart_upload['UploadId']\n",
    "        )\n",
    "        l = []\n",
    "        print(\"\\t Uploaded \\n\")\n",
    "    \n",
    "# Open the file for writing in binary mode\n",
    "print('Opening local file ' + big_files[1])\n",
    "file = open(big_files[1], 'wb')\n",
    "\n",
    "# Download the file a chunk at a time\n",
    "# Each chunk is sent to handleDownload\n",
    "# We append the chunk to the file and then print a '.' for progress\n",
    "# RETR is an FTP command\n",
    "print('Getting ' + big_files[1])\n",
    "ftp.retrbinary('RETR ' + big_files[1],custom_callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lambda Code \"Same as above\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-15T15:05:11.867098Z",
     "start_time": "2020-04-15T14:57:55.288Z"
    }
   },
   "outputs": [],
   "source": [
    "# from ftplib import FTP\n",
    "# import string\n",
    "# import pprint\n",
    "# import time\n",
    "# import boto3\n",
    "# import os\n",
    "# client = boto3.client('s3')\n",
    "\n",
    "\n",
    "# def lambda_handler(event, context):\n",
    "    \n",
    "#     try:\n",
    "\n",
    "#         ftp = FTP('13.233.66.93')\n",
    "#         ftp.login(user='test_user', passwd = 'rishabh')\n",
    "#         ftp.cwd('/files/ftp')\n",
    "#         ftp_files = ftp.nlst()\n",
    "#         #print(ftp_files,end='\\n')\n",
    "        \n",
    "        \n",
    "#         def filter_names(n) :\n",
    "#             if n.endswith('csv') :\n",
    "#                 return True\n",
    "#             else :\n",
    "#                 return False\n",
    "\n",
    "#         ftp_files = list(filter( filter_names, ftp_files ))\n",
    "#         #print(ftp_files)\n",
    "   \n",
    "#     except:\n",
    "#         print(\"Error connecting to FTP\")\n",
    "    \n",
    "#     try :\n",
    "#         s3_files = client.list_objects_v2(Bucket = 'rishabhsengar2611')\n",
    "#     except :\n",
    "#         print(\"No such Bucket \\n\")\n",
    "\n",
    "# # Returns some or all (up to 1,000) of the objects in a bucket\n",
    "#     pp = pprint.PrettyPrinter(indent=4)\n",
    "#     pp.pprint(s3_files)\n",
    "\n",
    "    \n",
    "    \n",
    "#     s3_files_names = []\n",
    "#     s3_files_size = []\n",
    "#     #print(\"File Name \\t Size\\n\")\n",
    "#     # Print the files\n",
    "#     try :\n",
    "#         for i in range( 0,len(s3_files['Contents']) ) :\n",
    "#             s3_files_names.append(s3_files['Contents'][i]['Key'])\n",
    "#             #print(s3_files['Contents'][i]['Key'], end='\\t')\n",
    "#             s3_files_size.append(s3_files['Contents'][i]['Size'])\n",
    "#             #print(s3_files['Contents'][i]['Size'], end='\\n')\n",
    "        \n",
    "#     except KeyError :\n",
    "#         print(\"Bucket is Empty\")\n",
    "\n",
    "\n",
    "    \n",
    "#     def filter_names(n) :\n",
    "#         if n in s3_files_names :\n",
    "#             return False\n",
    "#         else :\n",
    "#             return True\n",
    "\n",
    "#     ftp_files = list(filter( filter_names, ftp_files ))\n",
    "#     #print(ftp_files)\n",
    "\n",
    "    \n",
    "    \n",
    "#     ftp_size = {}\n",
    "#     for i in ftp_files :\n",
    "#         ftp_size[i] = ftp.size(i)\n",
    "#     #print(ftp_size)\n",
    "\n",
    "\n",
    "\n",
    "#     chunk_size = 6291456\n",
    "    \n",
    "    \n",
    "    \n",
    "#     big_files = []\n",
    "#     for file in ftp_size :\n",
    "#         if ftp_size[file] < chunk_size :\n",
    "#             localfile = os.path.join('/tmp/', file)\n",
    "            \n",
    "#             ftp.retrbinary('RETR ' + file, open( localfile, 'wb').write)\n",
    "#             print(\"retieved file :\\t\" + file,end='\\n' )\n",
    "            \n",
    "#             with open(localfile, 'rb') as data:\n",
    "#                 client.upload_fileobj(data, 'rishabhsengar2611', file)\n",
    "#             print(\"uploaded file :\\t\" + file,end='\\n')\n",
    "#             #os.remove(file)\n",
    "            \n",
    "#         else :\n",
    "#             big_files.append(file)\n",
    "#             print(\"big files :  \"+file+\"  -->  size :  \"+str(ftp_size[file]),end = '\\n')\n",
    "\n",
    "#     return \"Success\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "432.5px",
    "left": "910px",
    "right": "20px",
    "top": "120px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
