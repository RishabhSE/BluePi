{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries Used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-03T12:30:45.097002Z",
     "start_time": "2020-04-03T12:30:44.815766Z"
    }
   },
   "outputs": [],
   "source": [
    "from ftplib import FTP\n",
    "import string\n",
    "import os\n",
    "import time\n",
    "\n",
    "import pprint\n",
    "# prints the formatted representation of PrettyPrinter object\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "\n",
    "import boto3\n",
    "# Get the service client \n",
    "client = boto3.client('s3')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting FTP Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-03T12:30:45.254024Z",
     "start_time": "2020-04-03T12:30:45.098974Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'230 Logged on'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from ftplib import FTP\n",
    "\n",
    "# Domain name or server ip:\n",
    "ftp = FTP('13.233.66.93')\n",
    "\n",
    "ftp.login(user='test_user', passwd = 'rishabh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get all the file names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-03T12:30:45.442417Z",
     "start_time": "2020-04-03T12:30:45.270564Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   '9G9VYW23CU.csv',\n",
      "    'Big-Data-Landscape-2017.pdf',\n",
      "    'Big-Data-Landscape-2018.pdf',\n",
      "    'Big-Data-Landscape-2019.pdf',\n",
      "    'D029LRLIRA.csv',\n",
      "    'DN7A49XY69.csv',\n",
      "    'EDTMQD3VFB.csv',\n",
      "    'file.txt',\n",
      "    'GJNZEL7QS7.csv',\n",
      "    'Measurement_info.csv',\n",
      "    'Measurement_summary.csv',\n",
      "    'MOCK_DATA.json',\n",
      "    'N84NQPAZ5A.csv',\n",
      "    'people.json',\n",
      "    'SG75B3AMDD.csv',\n",
      "    'WMM6GGSTIQ.csv']\n"
     ]
    }
   ],
   "source": [
    "# Set the current directory on the server\n",
    "ftp.cwd('/files/ftp')\n",
    "\n",
    "# Return a list of file names\n",
    "ftp_files = ftp.nlst()\n",
    "\n",
    "# Printing\n",
    "pp.pprint(ftp_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get only CSV files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-03T12:30:45.483670Z",
     "start_time": "2020-04-03T12:30:45.453283Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   '9G9VYW23CU.csv',\n",
      "    'D029LRLIRA.csv',\n",
      "    'DN7A49XY69.csv',\n",
      "    'EDTMQD3VFB.csv',\n",
      "    'GJNZEL7QS7.csv',\n",
      "    'Measurement_info.csv',\n",
      "    'Measurement_summary.csv',\n",
      "    'N84NQPAZ5A.csv',\n",
      "    'SG75B3AMDD.csv',\n",
      "    'WMM6GGSTIQ.csv']\n"
     ]
    }
   ],
   "source": [
    "def filter_names(n) :\n",
    "    if n.endswith('csv') :\n",
    "        return True\n",
    "    else :\n",
    "        return False\n",
    "\n",
    "ftp_files = list(filter( filter_names, ftp_files ))\n",
    "\n",
    "# Printing\n",
    "pp.pprint(ftp_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Files which are already present in S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-03T12:30:45.775145Z",
     "start_time": "2020-04-03T12:30:45.491683Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   'Contents': [   {   'ETag': '\"90782d0821d06338747f7927e53e3d00\"',\n",
      "                        'Key': 'SG75B3AMDD.csv',\n",
      "                        'LastModified': datetime.datetime(2020, 4, 3, 8, 56, 35, tzinfo=tzutc()),\n",
      "                        'Size': 387,\n",
      "                        'StorageClass': 'STANDARD'},\n",
      "                    {   'ETag': '\"fb05fa19d0981b560475a6753d3b3faa\"',\n",
      "                        'Key': 'WMM6GGSTIQ.csv',\n",
      "                        'LastModified': datetime.datetime(2020, 4, 3, 8, 56, 35, tzinfo=tzutc()),\n",
      "                        'Size': 277,\n",
      "                        'StorageClass': 'STANDARD'},\n",
      "                    {   'ETag': '\"d3ee934d3c9219a2f5a9230551cbf182\"',\n",
      "                        'Key': 'file.txt',\n",
      "                        'LastModified': datetime.datetime(2020, 4, 2, 18, 13, 29, tzinfo=tzutc()),\n",
      "                        'Size': 319,\n",
      "                        'StorageClass': 'STANDARD'},\n",
      "                    {   'ETag': '\"9bcac1874c0a07eef4be75ea99e2272e\"',\n",
      "                        'Key': 'people.json',\n",
      "                        'LastModified': datetime.datetime(2020, 4, 2, 18, 13, 30, tzinfo=tzutc()),\n",
      "                        'Size': 1612897,\n",
      "                        'StorageClass': 'STANDARD'}],\n",
      "    'EncodingType': 'url',\n",
      "    'IsTruncated': False,\n",
      "    'KeyCount': 4,\n",
      "    'MaxKeys': 1000,\n",
      "    'Name': 'rishabhsengar2611',\n",
      "    'Prefix': '',\n",
      "    'ResponseMetadata': {   'HTTPHeaders': {   'content-type': 'application/xml',\n",
      "                                               'date': 'Fri, 03 Apr 2020 '\n",
      "                                                       '12:30:46 GMT',\n",
      "                                               'server': 'AmazonS3',\n",
      "                                               'transfer-encoding': 'chunked',\n",
      "                                               'x-amz-bucket-region': 'ap-south-1',\n",
      "                                               'x-amz-id-2': 'qcbAxG6UPSM7V2pyFaPfPNYPYC8OaW30M4ia1KljmbPnTnoCOTIF0j/PO5LM+3eROMPkUYgkZSc=',\n",
      "                                               'x-amz-request-id': '924B0F3CBAD771D8'},\n",
      "                            'HTTPStatusCode': 200,\n",
      "                            'HostId': 'qcbAxG6UPSM7V2pyFaPfPNYPYC8OaW30M4ia1KljmbPnTnoCOTIF0j/PO5LM+3eROMPkUYgkZSc=',\n",
      "                            'RequestId': '924B0F3CBAD771D8',\n",
      "                            'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "try :\n",
    "    # Returns some or all of the objects in a bucket\n",
    "    s3_files = client.list_objects_v2(Bucket = 'rishabhsengar2611')\n",
    "except :\n",
    "    # if wrong bucket name is entered\n",
    "    print(\"No such Bucket \\n\")\n",
    "\n",
    "pp.pprint(s3_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-03T12:30:45.782082Z",
     "start_time": "2020-04-03T12:30:45.777245Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SG75B3AMDD.csv'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dictionary Access to get the name of the first file\n",
    "s3_files['Contents'][0]['Key']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-03T12:30:45.791386Z",
     "start_time": "2020-04-03T12:30:45.786272Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "387"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dictionary Access to get the size of the first file\n",
    "s3_files['Contents'][0]['Size']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get S3 file names and there size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-03T12:30:45.807031Z",
     "start_time": "2020-04-03T12:30:45.795002Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Name \t\t Size\n",
      "\n",
      "SG75B3AMDD.csv\t\t387\n",
      "WMM6GGSTIQ.csv\t\t277\n",
      "file.txt\t\t319\n",
      "people.json\t\t1612897\n"
     ]
    }
   ],
   "source": [
    "# Used to store the s3 files names\n",
    "s3_files_names = []\n",
    "\n",
    "# Used to store the sizes of files\n",
    "s3_files_size = []\n",
    "\n",
    "print(\"File Name \\t\\t Size\\n\")\n",
    "# Print the files\n",
    "try :\n",
    "    for i in range( 0,len(s3_files['Contents']) ) :\n",
    "        s3_files_names.append(s3_files['Contents'][i]['Key'])\n",
    "        print(s3_files['Contents'][i]['Key'], end='\\t\\t')\n",
    "        s3_files_size.append(s3_files['Contents'][i]['Size'])\n",
    "        print(s3_files['Contents'][i]['Size'], end='\\n')\n",
    "        \n",
    "except KeyError :\n",
    "    print(\"Bucket is Empty\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove already present file in the s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-03T12:30:45.826400Z",
     "start_time": "2020-04-03T12:30:45.811497Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " To be Added\n",
      "[   '9G9VYW23CU.csv',\n",
      "    'D029LRLIRA.csv',\n",
      "    'DN7A49XY69.csv',\n",
      "    'EDTMQD3VFB.csv',\n",
      "    'GJNZEL7QS7.csv',\n",
      "    'Measurement_info.csv',\n",
      "    'Measurement_summary.csv',\n",
      "    'N84NQPAZ5A.csv']\n",
      "\n",
      " Already Present\n",
      "['SG75B3AMDD.csv', 'WMM6GGSTIQ.csv']\n"
     ]
    }
   ],
   "source": [
    "# Already present files\n",
    "s3_files_present = []\n",
    "\n",
    "def filter_names(n) :\n",
    "    if n in s3_files_names :\n",
    "        s3_files_present.append(n)\n",
    "        return False\n",
    "    else :\n",
    "        return True\n",
    "\n",
    "ftp_files = list(filter( filter_names, ftp_files ))\n",
    "\n",
    "\n",
    "print(\" To be Added\")\n",
    "pp.pprint(ftp_files)\n",
    "print(\"\\n Already Present\")\n",
    "pp.pprint(s3_files_present)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-03T12:30:46.063661Z",
     "start_time": "2020-04-03T12:30:45.829550Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   '9G9VYW23CU.csv': 354,\n",
      "    'D029LRLIRA.csv': 341,\n",
      "    'DN7A49XY69.csv': 467,\n",
      "    'EDTMQD3VFB.csv': 237,\n",
      "    'GJNZEL7QS7.csv': 316,\n",
      "    'Measurement_info.csv': 124452984,\n",
      "    'Measurement_summary.csv': 94076158,\n",
      "    'N84NQPAZ5A.csv': 429}\n"
     ]
    }
   ],
   "source": [
    "# Make the Dictionary of filename and Size\n",
    "ftp_size = {}\n",
    "for i in ftp_files :\n",
    "    ftp_size[i] = ftp.size(i)\n",
    "\n",
    "pp.pprint(ftp_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding files to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-03T12:30:46.068889Z",
     "start_time": "2020-04-03T12:30:46.065721Z"
    }
   },
   "outputs": [],
   "source": [
    "# Each part must be at least 5 MB in size\n",
    "# 1024*1024*6 == 6MB\n",
    "chunk_size = 6291456"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-03T12:30:46.083112Z",
     "start_time": "2020-04-03T12:30:46.071504Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9G9VYW23CU.csv\t\t354\n",
      "D029LRLIRA.csv\t\t341\n",
      "DN7A49XY69.csv\t\t467\n",
      "EDTMQD3VFB.csv\t\t237\n",
      "GJNZEL7QS7.csv\t\t316\n",
      "Measurement_info.csv\t\t124452984\n",
      "Measurement_summary.csv\t\t94076158\n",
      "N84NQPAZ5A.csv\t\t429\n"
     ]
    }
   ],
   "source": [
    "# ftp.size(ftp_files[0])\n",
    "for file in ftp_size :\n",
    "    print(file+\"\\t\\t\"+str(ftp_size[file]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Files which have size less than 6MB uploaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-03T12:30:47.299113Z",
     "start_time": "2020-04-03T12:30:46.085005Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retieved file :\t9G9VYW23CU.csv\n",
      "uploaded file :\t9G9VYW23CU.csv\n",
      "retieved file :\tD029LRLIRA.csv\n",
      "uploaded file :\tD029LRLIRA.csv\n",
      "retieved file :\tDN7A49XY69.csv\n",
      "uploaded file :\tDN7A49XY69.csv\n",
      "retieved file :\tEDTMQD3VFB.csv\n",
      "uploaded file :\tEDTMQD3VFB.csv\n",
      "retieved file :\tGJNZEL7QS7.csv\n",
      "uploaded file :\tGJNZEL7QS7.csv\n",
      "big files :  Measurement_info.csv  -->  size :  124452984\n",
      "big files :  Measurement_summary.csv  -->  size :  94076158\n",
      "retieved file :\tN84NQPAZ5A.csv\n",
      "uploaded file :\tN84NQPAZ5A.csv\n"
     ]
    }
   ],
   "source": [
    "# Used to store the large files\n",
    "big_files = []\n",
    "\n",
    "# This for loop is used to upload files\n",
    "for file in ftp_size :\n",
    "    if ftp_size[file] < chunk_size :\n",
    "        \n",
    "        # Change the location\n",
    "        local_file = os.path.join('/home/bluepi/Desktop/',file)\n",
    "        \n",
    "        # Retrieve a file in binary transfer mode\n",
    "        # RETR command --> A RETR request asks the server to send the contents of a file \n",
    "        #                       over the data connection already established by the client.\n",
    "        ftp.retrbinary('RETR ' + file, open(local_file, 'wb').write)\n",
    "        print(\"retieved file :\\t\" + file,end='\\n' )\n",
    "        \n",
    "        # Upload file in binary mode in s3 object\n",
    "        # Useful when we perform multipsrt upload\n",
    "        with open(local_file, 'rb') as data:\n",
    "            client.upload_fileobj(Fileobj=data, Bucket= 'rishabhsengar2611', Key= file)\n",
    "            \n",
    "        print(\"uploaded file :\\t\" + file,end='\\n')\n",
    "        #os.remove(file)\n",
    "    else :\n",
    "        big_files.append(file)\n",
    "        print(\"big files :  \"+file+\"  -->  size :  \"+str(ftp_size[file]),end = '\\n')\n",
    "        \n",
    "# Errors :-\n",
    "# Brokenpipeerror errno 32\n",
    "# ftplib.error_perm: 530 Login authentication failed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Files to be uploaded in chunks( Working on it )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-03T12:30:47.305662Z",
     "start_time": "2020-04-03T12:30:47.301121Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Measurement_info.csv', 'Measurement_summary.csv']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-03T12:30:47.312651Z",
     "start_time": "2020-04-03T12:30:47.307989Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Add these files in s3\n",
    "\n",
    "# # No of files present to add\n",
    "# no_of_files = len(ftp_files)\n",
    "\n",
    "# for i in range(0,no_of_files):\n",
    "\n",
    "# # Get the filename\n",
    "#     filename = ftp_files[i]\n",
    "\n",
    "# #\n",
    "#     localfile = open(filename, 'wb')\n",
    "#     ftp.retrbinary('RETR ' + filename, localfile.write)\n",
    "    \n",
    "# #\n",
    "# #     response = client.put_object(\n",
    "# #     ACL='private',\n",
    "# #     Body=filename, # Object data\n",
    "# #     Bucket='rishabhsengar2611', # Bucket name to which the PUT operation was initiated\n",
    "# #     Key=filename # Object key for which the PUT operation was initiated\n",
    "# #     )\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lambda Code \"Same as above\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-03T12:30:47.352058Z",
     "start_time": "2020-04-03T12:30:47.314522Z"
    }
   },
   "outputs": [],
   "source": [
    "from ftplib import FTP\n",
    "import string\n",
    "import pprint\n",
    "import time\n",
    "import boto3\n",
    "import os\n",
    "client = boto3.client('s3')\n",
    "\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "    \n",
    "    try:\n",
    "\n",
    "        ftp = FTP('13.233.66.93')\n",
    "        ftp.login(user='test_user', passwd = 'rishabh')\n",
    "        ftp.cwd('/files/ftp')\n",
    "        ftp_files = ftp.nlst()\n",
    "        #print(ftp_files,end='\\n')\n",
    "        \n",
    "        \n",
    "        def filter_names(n) :\n",
    "            if n.endswith('csv') :\n",
    "                return True\n",
    "            else :\n",
    "                return False\n",
    "\n",
    "        ftp_files = list(filter( filter_names, ftp_files ))\n",
    "        #print(ftp_files)\n",
    "   \n",
    "    except:\n",
    "        print(\"Error connecting to FTP\")\n",
    "    \n",
    "    try :\n",
    "        s3_files = client.list_objects_v2(Bucket = 'rishabhsengar2611')\n",
    "    except :\n",
    "        print(\"No such Bucket \\n\")\n",
    "\n",
    "# Returns some or all (up to 1,000) of the objects in a bucket\n",
    "    pp = pprint.PrettyPrinter(indent=4)\n",
    "    pp.pprint(s3_files)\n",
    "\n",
    "    \n",
    "    \n",
    "    s3_files_names = []\n",
    "    s3_files_size = []\n",
    "    #print(\"File Name \\t Size\\n\")\n",
    "    # Print the files\n",
    "    try :\n",
    "        for i in range( 0,len(s3_files['Contents']) ) :\n",
    "            s3_files_names.append(s3_files['Contents'][i]['Key'])\n",
    "            #print(s3_files['Contents'][i]['Key'], end='\\t')\n",
    "            s3_files_size.append(s3_files['Contents'][i]['Size'])\n",
    "            #print(s3_files['Contents'][i]['Size'], end='\\n')\n",
    "        \n",
    "    except KeyError :\n",
    "        print(\"Bucket is Empty\")\n",
    "\n",
    "\n",
    "    \n",
    "    def filter_names(n) :\n",
    "        if n in s3_files_names :\n",
    "            return False\n",
    "        else :\n",
    "            return True\n",
    "\n",
    "    ftp_files = list(filter( filter_names, ftp_files ))\n",
    "    #print(ftp_files)\n",
    "\n",
    "    \n",
    "    \n",
    "    ftp_size = {}\n",
    "    for i in ftp_files :\n",
    "        ftp_size[i] = ftp.size(i)\n",
    "    #print(ftp_size)\n",
    "\n",
    "\n",
    "\n",
    "    chunk_size = 6291456\n",
    "    \n",
    "    \n",
    "    \n",
    "    big_files = []\n",
    "    for file in ftp_size :\n",
    "        if ftp_size[file] < chunk_size :\n",
    "            localfile = os.path.join('/tmp/', file)\n",
    "            \n",
    "            ftp.retrbinary('RETR ' + file, open( localfile, 'wb').write)\n",
    "            print(\"retieved file :\\t\" + file,end='\\n' )\n",
    "            \n",
    "            with open(localfile, 'rb') as data:\n",
    "                client.upload_fileobj(data, 'rishabhsengar2611', file)\n",
    "            print(\"uploaded file :\\t\" + file,end='\\n')\n",
    "            #os.remove(file)\n",
    "            \n",
    "        else :\n",
    "            big_files.append(file)\n",
    "            print(\"big files :  \"+file+\"  -->  size :  \"+str(ftp_size[file]),end = '\\n')\n",
    "\n",
    "    return \"Success\"\n"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
