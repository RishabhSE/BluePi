{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latest Product Table\n",
    "\n",
    "- p_id from **1 to 100** already present in  main table, it can be updated and deleted\n",
    "- p_id from **101 to 200** can be inserted in to main table and after inserting it into main table it could also be deleted\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries Used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-10T06:25:16.330225Z",
     "start_time": "2020-04-10T06:25:16.313921Z"
    }
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "\n",
    "# Main entry point for DataFrame and SQL functionality.\n",
    "from pyspark.sql import SparkSession\n",
    "# Start SPARK Session\n",
    "spark = SparkSession.builder.appName('Basics').getOrCreate()\n",
    "\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the Main Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-10T06:25:21.186852Z",
     "start_time": "2020-04-10T06:25:16.332962Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read from main_table\n",
    "Table = spark.read.format('csv').options(\n",
    "    header=True, inferschema=True).load(\n",
    "        \"/home/bluepi/Downloads/Update/product_info/main table/main_table_new.csv\")\n",
    "\n",
    "# Add record type to main table\n",
    "Table_new = Table.withColumn('record_type', lit(\"A\"))\n",
    "\n",
    "# Write in main_table folder\n",
    "path = \"/home/bluepi/Downloads/Update/Updated Product/Latest Product/\"\n",
    "try:\n",
    "    Table_new.write.format('csv').save(\n",
    "        os.path.join(path, 'main_table'), header=True)\n",
    "except:\n",
    "    Table_new.write.mode('overwrite').format('csv').save(\n",
    "        os.path.join(path, 'main_table'), header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-10T06:25:21.208152Z",
     "start_time": "2020-04-10T06:25:21.198564Z"
    }
   },
   "outputs": [],
   "source": [
    "# GFG\n",
    "class my_dictionary(dict):\n",
    "\n",
    "    # __init__ function\n",
    "    def __init__(self):\n",
    "        self = dict()\n",
    "\n",
    "    # Function to add key:value\n",
    "    def add(self, key, value):\n",
    "        self[key] = value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-10T06:25:58.257307Z",
     "start_time": "2020-04-10T06:25:21.210818Z"
    },
    "run_control": {
     "marked": false
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " File read from --\n",
      "/home/bluepi/Downloads/Update/Updated Product/Latest Product/main_table\n",
      "\n",
      "\t\\ Date ----> 31-03-2020\n",
      "\n",
      "Main_Table Count ----> 100\n",
      "Total \"Inserted I\"----> 9\n",
      "After Inserting----> 109\n",
      "121 126 130 139 149 165 174 176 192\n",
      "\n",
      "\n",
      "TO Be Update\"per_day_data\"\n",
      "26 30 32 36 40 42 45 45 55 56 58 68 86\n",
      "Update Count ------>13\n",
      "\n",
      "\n",
      "\n",
      "Total Deleted ------>9\n",
      "5 8 15 17 22 43 85 87 93\n",
      "After Deleting Count---->100\n",
      "\n",
      " Main Table Stored \n",
      "/home/bluepi/Downloads/Update/Updated Product/Latest Product/main_table31-03-2020\n",
      "\n",
      "***************************************************************************************\n",
      "\n",
      "\n",
      " File read from --\n",
      "/home/bluepi/Downloads/Update/Updated Product/Latest Product/main_table31-03-2020\n",
      "\n",
      "\t\\ Date ----> 01-04-2020\n",
      "\n",
      "Main_Table Count ----> 100\n",
      "Total \"Inserted I\"----> 10\n",
      "After Inserting----> 110\n",
      "109 122 152 156 161 170 172 188 198 200\n",
      "\n",
      "\n",
      "TO Be Update\"per_day_data\"\n",
      "13 13 18 38 48 52 59 67 79 80 81 81 82 90 90 90 96 99\n",
      "Update Count ------>18\n",
      "\n",
      "\n",
      "\n",
      "Total Deleted ------>9\n",
      "2 16 29 49 74 77 84 89 139\n",
      "After Deleting Count---->101\n",
      "\n",
      " Main Table Stored \n",
      "/home/bluepi/Downloads/Update/Updated Product/Latest Product/main_table01-04-2020\n",
      "\n",
      "***************************************************************************************\n",
      "\n",
      "\n",
      " File read from --\n",
      "/home/bluepi/Downloads/Update/Updated Product/Latest Product/main_table01-04-2020\n",
      "\n",
      "\t\\ Date ----> 02-04-2020\n",
      "\n",
      "Main_Table Count ----> 101\n",
      "Total \"Inserted I\"----> 9\n",
      "After Inserting----> 110\n",
      "124 131 141 157 163 164 178 189 195\n",
      "\n",
      "\n",
      "TO Be Update\"per_day_data\"\n",
      "6 12 18 20 24 28 35 35 36 44 45 61 65 73 81 126 156 161 174 174 178 188 189 195\n",
      "Update Count ------>24\n",
      "\n",
      "\n",
      "\n",
      "Total Deleted ------>1\n",
      "198\n",
      "After Deleting Count---->109\n",
      "\n",
      " Main Table Stored \n",
      "/home/bluepi/Downloads/Update/Updated Product/Latest Product/main_table02-04-2020\n",
      "\n",
      "***************************************************************************************\n",
      "\n",
      "\n",
      " File read from --\n",
      "/home/bluepi/Downloads/Update/Updated Product/Latest Product/main_table02-04-2020\n",
      "\n",
      "\t\\ Date ----> 03-04-2020\n",
      "\n",
      "Main_Table Count ----> 109\n",
      "Total \"Inserted I\"----> 8\n",
      "After Inserting----> 117\n",
      "103 105 137 146 160 162 175 199\n",
      "\n",
      "\n",
      "TO Be Update\"per_day_data\"\n",
      "1 28 30 31 31 32 37 40 41 45 57 60 60 94 124 126 162 164 176 178 195\n",
      "Update Count ------>21\n",
      "\n",
      "\n",
      "\n",
      "Total Deleted ------>5\n",
      "57 76 94 156 172\n",
      "After Deleting Count---->112\n",
      "\n",
      " Main Table Stored \n",
      "/home/bluepi/Downloads/Update/Updated Product/Latest Product/main_table03-04-2020\n",
      "\n",
      "***************************************************************************************\n",
      "\n",
      "\n",
      " File read from --\n",
      "/home/bluepi/Downloads/Update/Updated Product/Latest Product/main_table03-04-2020\n",
      "\n",
      "\t\\ Date ----> 04-04-2020\n",
      "\n",
      "Main_Table Count ----> 112\n",
      "Total \"Inserted I\"----> 8\n",
      "After Inserting----> 120\n",
      "115 117 136 148 155 173 183 197\n",
      "\n",
      "\n",
      "TO Be Update\"per_day_data\"\n",
      "21 21 69 70 72 73 149 157 161 188 199\n",
      "Update Count ------>11\n",
      "\n",
      "\n",
      "\n",
      "Total Deleted ------>8\n",
      "1 6 9 18 67 79 81 174\n",
      "After Deleting Count---->112\n",
      "\n",
      " Main Table Stored \n",
      "/home/bluepi/Downloads/Update/Updated Product/Latest Product/main_table04-04-2020\n",
      "\n",
      "***************************************************************************************\n",
      "\n",
      "\n",
      " File read from --\n",
      "/home/bluepi/Downloads/Update/Updated Product/Latest Product/main_table04-04-2020\n",
      "\n",
      "\t\\ Date ----> 05-04-2020\n",
      "\n",
      "Main_Table Count ----> 112\n",
      "Total \"Inserted I\"----> 9\n",
      "After Inserting----> 121\n",
      "112 116 125 158 167 171 179 190 196\n",
      "\n",
      "\n",
      "TO Be Update\"per_day_data\"\n",
      "20 25 26 36 38 52 54 58 58 64 65 69 70 71 73 78 78 95 109 122 148 183 189 196 200\n",
      "Update Count ------>25\n",
      "\n",
      "\n",
      "\n",
      "Total Deleted ------>7\n",
      "13 24 68 73 146 146 155\n",
      "After Deleting Count---->115\n",
      "\n",
      " Main Table Stored \n",
      "/home/bluepi/Downloads/Update/Updated Product/Latest Product/main_table05-04-2020\n",
      "\n",
      "***************************************************************************************\n",
      "\n",
      "\n",
      " File read from --\n",
      "/home/bluepi/Downloads/Update/Updated Product/Latest Product/main_table05-04-2020\n",
      "\n",
      "\t\\ Date ----> 06-04-2020\n",
      "\n",
      "Main_Table Count ----> 115\n",
      "Total \"Inserted I\"----> 11\n",
      "After Inserting----> 126\n",
      "108 114 123 128 135 143 154 154 177 181 191\n",
      "\n",
      "\n",
      "TO Be Update\"per_day_data\"\n",
      "7 11 11 12 35 35 41 45 50 55 59 60 70 80 97 158 160 167 175 177 192 192\n",
      "Update Count ------>22\n",
      "\n",
      "\n",
      "\n",
      "Total Deleted ------>10\n",
      "3 4 30 63 88 100 115 128 176 188\n",
      "After Deleting Count---->116\n",
      "\n",
      " Main Table Stored \n",
      "/home/bluepi/Downloads/Update/Updated Product/Latest Product/main_table06-04-2020\n",
      "\n",
      "***************************************************************************************\n",
      "\n",
      "\n",
      " File read from --\n",
      "/home/bluepi/Downloads/Update/Updated Product/Latest Product/main_table06-04-2020\n",
      "\n",
      "\t\\ Date ----> 07-04-2020\n",
      "\n",
      "Main_Table Count ----> 116\n",
      "Total \"Inserted I\"----> 9\n",
      "After Inserting----> 125\n",
      "102 104 107 119 151 168 169 194 194\n",
      "\n",
      "\n",
      "TO Be Update\"per_day_data\"\n",
      "10 19 32 32 51 71 75 82 104 121 130 164 191 196 200 200\n",
      "Update Count ------>16\n",
      "\n",
      "\n",
      "\n",
      "16 is going to be deleted again\n",
      "\n",
      "\n",
      "13 is going to be deleted again\n",
      "\n",
      "\n",
      "Total Deleted ------>9\n",
      "26 34 96 103 125 158 161 171 190\n",
      "After Deleting Count---->116\n",
      "\n",
      " Main Table Stored \n",
      "/home/bluepi/Downloads/Update/Updated Product/Latest Product/main_table07-04-2020\n",
      "\n",
      "***************************************************************************************\n",
      "\n",
      "\n",
      " File read from --\n",
      "/home/bluepi/Downloads/Update/Updated Product/Latest Product/main_table07-04-2020\n",
      "\n",
      "\t\\ Date ----> 08-04-2020\n",
      "\n",
      "Main_Table Count ----> 116\n",
      "Total \"Inserted I\"----> 11\n",
      "After Inserting----> 127\n",
      "101 106 111 138 145 150 153 159 180 186 187\n",
      "\n",
      "\n",
      "TO Be Update\"per_day_data\"\n",
      "27 31 36 36 39 51 98 178 187 194 199\n",
      "Update Count ------>11\n",
      "\n",
      "\n",
      "\n",
      "13 is going to be deleted again\n",
      "\n",
      "\n",
      "158 is going to be deleted again\n",
      "\n",
      "\n",
      "Total Deleted ------>4\n",
      "59 66 135 149\n",
      "After Deleting Count---->122\n",
      "\n",
      " Main Table Stored \n",
      "/home/bluepi/Downloads/Update/Updated Product/Latest Product/main_table08-04-2020\n",
      "\n",
      "***************************************************************************************\n",
      "\n",
      "\n",
      " File read from --\n",
      "/home/bluepi/Downloads/Update/Updated Product/Latest Product/main_table08-04-2020\n",
      "\n",
      "\t\\ Date ----> 09-04-2020\n",
      "\n",
      "Main_Table Count ----> 122\n",
      "Total \"Inserted I\"----> 11\n",
      "After Inserting----> 133\n",
      "113 118 120 127 129 133 142 142 147 166 182\n",
      "\n",
      "\n",
      "TO Be Update\"per_day_data\"\n",
      "21 23 27 35 54 56 70 78 101 105 106 109 122 136 138 143 151 166 168 173 186 194 197 199\n",
      "Update Count ------>24\n",
      "\n",
      "\n",
      "\n",
      "Total Deleted ------>7\n",
      "37 52 54 83 97 122 192\n",
      "After Deleting Count---->126\n",
      "\n",
      " Main Table Stored \n",
      "/home/bluepi/Downloads/Update/Updated Product/Latest Product/main_table09-04-2020\n",
      "\n",
      "***************************************************************************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Storing all the \"p_id as value\" in a dictionary with \"date as key\", which we have inserted,deleted & updated            \n",
    "total_products_updated = my_dictionary()\n",
    "total_products_inserted = my_dictionary()\n",
    "total_products_deleted = my_dictionary()\n",
    "\n",
    "# Storing all the p_id in a list which we have deleted and inserted\n",
    "total_products_inserted_list = []\n",
    "total_products_deleted_list = []\n",
    "\n",
    "# ###################################################################################################\n",
    "\n",
    "for i in range(10, 0, -1):\n",
    "\n",
    "    data_schema = [\n",
    "        StructField('p_id', IntegerType(), True),\n",
    "        StructField('p_name', StringType(), True),\n",
    "        StructField('price', IntegerType(), True),\n",
    "        StructField('date_timestamp', TimestampType(), True),\n",
    "        StructField('record_type', StringType(), True)\n",
    "    ]\n",
    "    # Schema which we are accepting\n",
    "    final_struc = StructType(fields=data_schema)\n",
    "\n",
    "    # In this try-catch block we are only taking the previous day data, but initially there is\n",
    "    # no previous day, therefore we are taking main table at begining\n",
    "    try:\n",
    "        path1 = os.path.join(\n",
    "            \"/home/bluepi/Downloads/Update/Updated Product/Latest Product/\", t)\n",
    "        try:\n",
    "            os.remove(os.path.join(path1, '_SUCCESS'))\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        mainTable = spark.read.csv(path1, header=True, schema=final_struc)\n",
    "    except:\n",
    "        path1 = os.path.join(\n",
    "            \"/home/bluepi/Downloads/Update/Updated Product/Latest Product/\", \"main_table\")\n",
    "        try:\n",
    "            os.remove(os.path.join(path1, '_SUCCESS'))\n",
    "        except:\n",
    "            pass\n",
    "        mainTable = spark.read.csv(path1, header=True, schema=final_struc)\n",
    "\n",
    "    print(\"\\n File read from --\")\n",
    "    print(path1, end='\\n')\n",
    "\n",
    "    # Address to the product_info folder\n",
    "    address = \"/home/bluepi/Downloads/Update/product_info/\"\n",
    "    previous_day = (datetime.datetime.today() -\n",
    "                    datetime.timedelta(days=i)).strftime('%d-%m-%Y')\n",
    "    print(\"\\n\\t\\ Date ----> \"+previous_day+\"\\n\")\n",
    "\n",
    "    # before_insert = str(mainTable.count())\n",
    "    print(\"Main_Table Count ----> \" + str(mainTable.count()))\n",
    "\n",
    "    # Address to the Previous Day folder\n",
    "    new_address = address + previous_day\n",
    "#     print(\"\\nNew Address to read the folder ---->\"+new_address)\n",
    "\n",
    "# ###################################################################################################\n",
    "\n",
    "    # Read the Previous Day folder\n",
    "    per_day_data = spark.read.format('csv') \\\n",
    "        .options(header=True, inferschema=True) \\\n",
    "        .load(new_address)\n",
    "\n",
    "    # Get the list of p_id which we have to inserted in the main table\n",
    "    to_be_inserted = per_day_data.filter(\"record_type == 'I' \").collect()\n",
    "    p_id_list_I = [i.p_id for i in to_be_inserted]\n",
    "    \n",
    "    # Since we don't want our Inserted product to be Inserted again\n",
    "    for i in total_products_inserted_list :\n",
    "        if i in p_id_list_I :\n",
    "            print(\"\\n{} is going to be inserted again\\n\".format(i))\n",
    "            # Therefore removing already inserted products\n",
    "            p_id_list_I.remove(i)\n",
    "    # Storing all the p_id in a list which we have inserted\n",
    "    total_products_inserted_list.extend(p_id_list_I)\n",
    "\n",
    "    # Directly append new Inserted products\n",
    "    mainTable_I_inserted = mainTable.union(\n",
    "        per_day_data.filter(\"record_type == 'I' \"))\n",
    "\n",
    "    after_insert = str(mainTable_I_inserted.count())\n",
    "    total_insert = str(per_day_data.filter(\"record_type == 'I' \").count())\n",
    "\n",
    "    print(\"Total \\\"Inserted I\\\"----> \" + total_insert)\n",
    "    print(\"After Inserting----> \" + after_insert)\n",
    "\n",
    "    # Storing all the \"p_id as value\" in a dictionary with \"date as key\", which we have inserted\n",
    "    total_products_inserted.add(previous_day, p_id_list_I)\n",
    "    p_id_list_I.sort()\n",
    "    print(\" \".join(map(str, p_id_list_I)))\n",
    "    print(\"\\n\")\n",
    "\n",
    "# ###################################################################################################\n",
    "\n",
    "# Created a new DataFrame of records to be updated\n",
    "    from_per_day_data_U = per_day_data.filter(\"record_type == 'U' \")\n",
    "    \n",
    "# Get the list of p_id which we have to update taken from dated folders\n",
    "    from_per_day_data_U_list = from_per_day_data_U.select(\"p_id\").collect()\n",
    "\n",
    "# List comprehension\n",
    "    p_id_list_U = [i.p_id for i in from_per_day_data_U_list]\n",
    "    p_id_list_U.sort()\n",
    "    print(\"TO Be Update\\\"per_day_data\\\"\")\n",
    "    print(\" \".join(map(str, p_id_list_U)))\n",
    "#     print(p_id_list_U)\n",
    "\n",
    "    # Storing all the \"p_id as value\" in a dictionary with \"date as key\", which we have updated\n",
    "    total_products_updated.add(previous_day, p_id_list_U)\n",
    "\n",
    "    total_update = str(len((p_id_list_U)))\n",
    "    print(\"Update Count ------>\"+total_update)\n",
    "    print(\"\\n\")\n",
    "    \n",
    "# Get the products which we have to update, present in Main Table\n",
    "    from_mainTable_U = mainTable_I_inserted.filter(\n",
    "        col('p_id').isin(p_id_list_U))\n",
    "\n",
    "    # Performed Union operation on the above tables\n",
    "    mT_and_pDD_union = from_mainTable_U.union(from_per_day_data_U)\n",
    "#     mT_and_pDD_union.orderBy(mT_and_pDD_union.p_id).show()\n",
    "\n",
    "    # Performed GroupBy operation on P_ID and take the latest date only\n",
    "    #    Rename the columns\n",
    "    for_join_mT_and_pDD = mT_and_pDD_union.groupBy(\"p_id\").agg(\n",
    "        {\"date_timestamp\": \"max\"}).withColumnRenamed(\"max(date_timestamp)\", \"date_timestamp_1\")\n",
    "    for_join_mT_and_pDD = for_join_mT_and_pDD.withColumnRenamed(\n",
    "        \"p_id\", \"p_id_1\")\n",
    "#     for_join_mT_and_pDD.show()\n",
    "\n",
    "    # Performed Join operation to pick only latest updates only\n",
    "    joined = mT_and_pDD_union.join(for_join_mT_and_pDD, (\n",
    "        mT_and_pDD_union.p_id == for_join_mT_and_pDD.p_id_1) & (\n",
    "            mT_and_pDD_union.date_timestamp == for_join_mT_and_pDD.date_timestamp_1), 'inner')\n",
    "\n",
    "    joined = joined.select(\n",
    "        ['p_id', 'p_name', 'price', 'date_timestamp', 'record_type'])\n",
    "#     joined.count()\n",
    "\n",
    "    # First remove the p_id from Main_Table which we have to updated\n",
    "    mainTable_U_updated = mainTable_I_inserted.filter(\n",
    "        ~col('p_id').isin(p_id_list_U))\n",
    "#     mainTable_U_updated.orderBy(\"p_id\").count()\n",
    "\n",
    "    # Then Add the Updated P_ID to the Main_Table\n",
    "    mainTable_U_updated_new = mainTable_U_updated.union(joined)\n",
    "#     after_update = str(mainTable_U_updated_new.orderBy(\"p_id\").count())\n",
    "#     mainTable_U_updated_new.orderBy(\"p_id\").count()\n",
    "\n",
    "# ###################################################################################################\n",
    "\n",
    "    # Get the list of p_id which we have to delete\n",
    "    to_be_deleted = per_day_data.filter(\"record_type == 'D' \").collect()\n",
    "    p_id_list_D = [i.p_id for i in to_be_deleted]\n",
    "    \n",
    "    # Since we don't want our deleted product to be deleted again\n",
    "    for i in total_products_deleted_list :\n",
    "        if i in p_id_list_D :\n",
    "            print(\"\\n{} is going to be deleted again\\n\".format(i))\n",
    "            # Therefore removing already deleted products\n",
    "            p_id_list_D.remove(i)\n",
    "    # Storing all the p_id in a list which we have deleted            \n",
    "    total_products_deleted_list.extend(p_id_list_D)\n",
    "            \n",
    "    \n",
    "    # Storing all the \"p_id as value\" in a dictionary with \"date as key\", which we have deleted\n",
    "    total_products_deleted.add(previous_day, p_id_list_D)\n",
    "    \n",
    "\n",
    "#     print(\"\\nList of p_id which we have to deleted taken from \\\"per_day_data\\\"\")\n",
    "#     print(p_id_list_D)\n",
    "    total_deleted = str(len((p_id_list_D)))\n",
    "    p_id_list_D.sort()\n",
    "    print(\"\\nTotal Deleted ------>\"+str(len((p_id_list_D))))\n",
    "    print(\" \".join(map(str, p_id_list_D)))\n",
    "\n",
    "    # Remove the deleted p_id from main_table\n",
    "    mainTable_D_deleted = mainTable_U_updated_new.filter(\n",
    "        ~col('p_id').isin(p_id_list_D))\n",
    "\n",
    "    after_delete = str(mainTable_D_deleted.count())\n",
    "    print(\"After Deleting Count---->\"+after_delete)\n",
    "    \n",
    "\n",
    "# ###################################################################################################\n",
    "\n",
    "    # This writes the DF in different files becaues of parallism\n",
    "    t = \"main_table\"+str(previous_day)\n",
    "#     print(t,end=\"\\n\")\n",
    "\n",
    "#     try:\n",
    "    mainTable_D_deleted.write.format('csv').save(\n",
    "            os.path.join(path, t), header=True)\n",
    "#         print(\"\\n Main Table Stored (overwritten-NO)\")\n",
    "#     except:\n",
    "#         mainTable_D_deleted.write.mode('overwrite').format(\n",
    "#             'csv').save(os.path.join(path, t), header=True)\n",
    "#         print(\"\\n Main Table Stored (overwritten-YES)\")\n",
    "\n",
    "    print(\"\\n Main Table Stored \")\n",
    "    print(os.path.join(path, t))\n",
    "\n",
    "    print(\"\\n***************************************************************************************\\n\")\n",
    "#     input(\"Press Enter to continue...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Products Updated more than once in one day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-10T06:25:59.672019Z",
     "start_time": "2020-04-10T06:25:58.259374Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+-----+-------------------+-----------+\n",
      "|p_id|    p_name|price|     date_timestamp|record_type|\n",
      "+----+----------+-----+-------------------+-----------+\n",
      "|  21|Trippledex|  277|2020-04-03 09:28:03|          U|\n",
      "|  21|Trippledex|  618|2020-04-08 15:42:48|          U|\n",
      "|  23|     Subin|  213|2020-04-08 22:00:47|          U|\n",
      "|  23|     Subin|  408|2020-01-27 15:36:03|          A|\n",
      "|  27|   Konklux| 1389|2020-04-07 15:30:37|          U|\n",
      "|  27|   Konklux| 1079|2020-04-08 15:58:38|          U|\n",
      "|  35| Cardguard|  583|2020-04-08 03:24:19|          U|\n",
      "|  35| Cardguard|  686|2020-04-05 09:27:10|          U|\n",
      "|  54| Voyatouch|  232|2020-04-04 03:34:25|          U|\n",
      "|  54| Voyatouch| 1282|2020-04-08 21:25:24|          U|\n",
      "|  56| Voyatouch|  330|2020-04-08 03:21:29|          U|\n",
      "|  56| Voyatouch|  253|2020-03-30 21:34:20|          U|\n",
      "|  70|Voltsillam|  283|2020-04-05 15:49:35|          U|\n",
      "|  70|Voltsillam|  710|2020-04-08 03:45:08|          U|\n",
      "|  78|        It| 1252|2020-04-04 15:41:26|          U|\n",
      "|  78|        It| 1030|2020-04-08 09:54:23|          U|\n",
      "| 101|    Bigtax|  594|2020-04-07 09:30:19|          I|\n",
      "| 101|    Bigtax|  369|2020-04-08 03:35:30|          U|\n",
      "| 105|  Tres-Zap|  712|2020-04-02 09:34:40|          I|\n",
      "| 105|  Tres-Zap|  407|2020-04-08 15:56:55|          U|\n",
      "+----+----------+-----+-------------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "l = mT_and_pDD_union.groupBy(\"p_id\").agg({'p_id':'count'}).filter(\"count(p_id)>1\").select('p_id').collect()\n",
    "l1 = [ i.p_id for i in l]\n",
    "mT_and_pDD_union.filter( col('p_id').isin(l1) ).orderBy(col('p_id')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Main Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-10T06:26:00.917003Z",
     "start_time": "2020-04-10T06:25:59.676034Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----------+-----+-------------------+-----------+\n",
      "|p_id|     p_name|price|     date_timestamp|record_type|\n",
      "+----+-----------+-----+-------------------+-----------+\n",
      "|  21| Trippledex|  618|2020-04-08 15:42:48|          U|\n",
      "|  23|      Subin|  213|2020-04-08 22:00:47|          U|\n",
      "|  27|    Konklux| 1079|2020-04-08 15:58:38|          U|\n",
      "|  35|  Cardguard|  583|2020-04-08 03:24:19|          U|\n",
      "|  56|  Voyatouch|  330|2020-04-08 03:21:29|          U|\n",
      "|  70| Voltsillam|  710|2020-04-08 03:45:08|          U|\n",
      "|  78|         It| 1030|2020-04-08 09:54:23|          U|\n",
      "| 101|     Bigtax|  369|2020-04-08 03:35:30|          U|\n",
      "| 105|   Tres-Zap|  407|2020-04-08 15:56:55|          U|\n",
      "| 106|     Vagram|  909|2020-04-08 15:45:31|          U|\n",
      "| 109|  Holdlamis|  610|2020-04-08 03:41:22|          U|\n",
      "| 136|        Job| 1258|2020-04-08 15:50:41|          U|\n",
      "| 138|    Cardify| 1342|2020-04-08 09:53:58|          U|\n",
      "| 143|       Span| 1497|2020-04-08 15:22:24|          U|\n",
      "| 151|    Sonsing|  457|2020-04-08 09:18:35|          U|\n",
      "| 166|      Otcom| 1238|2020-04-08 21:28:13|          U|\n",
      "| 168|     Zathin| 1079|2020-04-08 09:33:37|          U|\n",
      "| 173|     Bamity|  210|2020-04-08 15:28:31|          U|\n",
      "| 186|Mat Lam Tam| 1049|2020-04-08 15:51:28|          U|\n",
      "| 194|     Keylex|  552|2020-04-08 21:40:32|          U|\n",
      "+----+-----------+-----+-------------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mainTable_D_deleted.filter( col('p_id').isin(l1) ).orderBy(col('p_id')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-10T06:26:00.942994Z",
     "start_time": "2020-04-10T06:26:00.921985Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'31-03-2020'\n",
      "inserted :\t\n",
      "121 126 130 139 149 165 174 176 192\n",
      "updated :\t\n",
      "26 30 32 36 40 42 45 45 55 56 58 68 86\n",
      "deleted :\t\n",
      "5 8 15 17 22 43 85 87 93\n",
      "\n",
      "\n",
      "'01-04-2020'\n",
      "inserted :\t\n",
      "109 122 152 156 161 170 172 188 198 200\n",
      "updated :\t\n",
      "13 13 18 38 48 52 59 67 79 80 81 81 82 90 90 90 96 99\n",
      "deleted :\t\n",
      "2 16 29 49 74 77 84 89 139\n",
      "\n",
      "\n",
      "'02-04-2020'\n",
      "inserted :\t\n",
      "124 131 141 157 163 164 178 189 195\n",
      "updated :\t\n",
      "6 12 18 20 24 28 35 35 36 44 45 61 65 73 81 126 156 161 174 174 178 188 189 195\n",
      "deleted :\t\n",
      "198\n",
      "\n",
      "\n",
      "'03-04-2020'\n",
      "inserted :\t\n",
      "103 105 137 146 160 162 175 199\n",
      "updated :\t\n",
      "1 28 30 31 31 32 37 40 41 45 57 60 60 94 124 126 162 164 176 178 195\n",
      "deleted :\t\n",
      "57 76 94 156 172\n",
      "\n",
      "\n",
      "'04-04-2020'\n",
      "inserted :\t\n",
      "115 117 136 148 155 173 183 197\n",
      "updated :\t\n",
      "21 21 69 70 72 73 149 157 161 188 199\n",
      "deleted :\t\n",
      "1 6 9 18 67 79 81 174\n",
      "\n",
      "\n",
      "'05-04-2020'\n",
      "inserted :\t\n",
      "112 116 125 158 167 171 179 190 196\n",
      "updated :\t\n",
      "20 25 26 36 38 52 54 58 58 64 65 69 70 71 73 78 78 95 109 122 148 183 189 196 200\n",
      "deleted :\t\n",
      "13 24 68 73 146 146 155\n",
      "\n",
      "\n",
      "'06-04-2020'\n",
      "inserted :\t\n",
      "108 114 123 128 135 143 154 154 177 181 191\n",
      "updated :\t\n",
      "7 11 11 12 35 35 41 45 50 55 59 60 70 80 97 158 160 167 175 177 192 192\n",
      "deleted :\t\n",
      "3 4 30 63 88 100 115 128 176 188\n",
      "\n",
      "\n",
      "'07-04-2020'\n",
      "inserted :\t\n",
      "102 104 107 119 151 168 169 194 194\n",
      "updated :\t\n",
      "10 19 32 32 51 71 75 82 104 121 130 164 191 196 200 200\n",
      "deleted :\t\n",
      "26 34 96 103 125 158 161 171 190\n",
      "\n",
      "\n",
      "'08-04-2020'\n",
      "inserted :\t\n",
      "101 106 111 138 145 150 153 159 180 186 187\n",
      "updated :\t\n",
      "27 31 36 36 39 51 98 178 187 194 199\n",
      "deleted :\t\n",
      "59 66 135 149\n",
      "\n",
      "\n",
      "'09-04-2020'\n",
      "inserted :\t\n",
      "113 118 120 127 129 133 142 142 147 166 182\n",
      "updated :\t\n",
      "21 23 27 35 54 56 70 78 101 105 106 109 122 136 138 143 151 166 168 173 186 194 197 199\n",
      "deleted :\t\n",
      "37 52 54 83 97 122 192\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "# prints the formatted representation of PrettyPrinter object\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "for i in range(10,0,-1) :\n",
    "    previous_day = (datetime.datetime.today() - datetime.timedelta(days=i)).strftime('%d-%m-%Y')\n",
    "    pp.pprint(previous_day)\n",
    "    print(\"inserted :\\t\")\n",
    "    print(' '.join(map(str, total_products_inserted.get(previous_day))))\n",
    "#     pp.pprint(total_products_inserted.get(previous_day))\n",
    "    print(\"updated :\\t\")\n",
    "    print(' '.join(map(str, total_products_updated.get(previous_day))))\n",
    "#     pp.pprint(total_products_updated.get(previous_day))\n",
    "    print(\"deleted :\\t\")\n",
    "    print(' '.join(map(str, total_products_deleted.get(previous_day))))\n",
    "#     pp.pprint(total_products_deleted.get(previous_day))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-10T06:26:00.950127Z",
     "start_time": "2020-04-10T06:26:00.945521Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2 3 4 5 6 8 9 13 15 16 17 18 22 24 26 29 30 34 37 43 49 52 54 57 59 63 66 67 68 73 74 76 77 79 81 83 84 85 87 88 89 93 94 96 97 100 103 115 122 125 128 135 139 146 146 149 155 156 158 161 171 172 174 176 188 190 192 198\n"
     ]
    }
   ],
   "source": [
    "total_products_deleted_list.sort()\n",
    "print(' '.join(map(str,total_products_deleted_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-10T06:26:00.961072Z",
     "start_time": "2020-04-10T06:26:00.952459Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101 102 103 104 105 106 107 108 109 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 133 135 136 137 138 139 141 142 142 143 145 146 147 148 149 150 151 152 153 154 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 186 187 188 189 190 191 192 194 194 195 196 197 198 199 200\n"
     ]
    }
   ],
   "source": [
    "total_products_inserted_list.sort()\n",
    "print(' '.join(map(str,total_products_inserted_list)))"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
