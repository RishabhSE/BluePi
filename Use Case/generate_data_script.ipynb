{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-08T15:02:02.658522Z",
     "start_time": "2020-04-08T15:02:02.401306Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import datetime\n",
    "import string\n",
    "\n",
    "# import data\n",
    "data = pd.read_csv(\n",
    "    \"/home/bluepi/Downloads/Update/product_info/main table/product_info.csv\")\n",
    "new_product = pd.read_csv(\n",
    "    \"/home/bluepi/Downloads/Update/product_info/main table/new_added.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-08T15:02:03.467758Z",
     "start_time": "2020-04-08T15:02:02.660430Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder name ---> 29-03-2020\n",
      "folder name ---> 30-03-2020\n",
      "folder name ---> 31-03-2020\n",
      "folder name ---> 01-04-2020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bluepi/.local/lib/python3.7/site-packages/ipykernel_launcher.py:193: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/bluepi/.local/lib/python3.7/site-packages/ipykernel_launcher.py:197: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder name ---> 02-04-2020\n",
      "folder name ---> 03-04-2020\n",
      "folder name ---> 04-04-2020\n",
      "folder name ---> 05-04-2020\n",
      "folder name ---> 06-04-2020\n",
      "folder name ---> 07-04-2020\n"
     ]
    }
   ],
   "source": [
    "# Products which have been deleted\n",
    "deleted_product = []\n",
    "\n",
    "\n",
    "# Getting list of all products present in main product table\n",
    "data_pid = data['p_id'].tolist()\n",
    "\n",
    "# *****************************************************************************************\n",
    "\n",
    "# This for-loop is created date wise directories in incremental order\n",
    "# If you want data of past 10 days\n",
    "for i in range(10, 0, -1):\n",
    "    \n",
    "    # Get the current time\n",
    "    now = datetime.datetime.now()\n",
    "    # Get the current date\n",
    "    current_date = datetime.datetime.now() - datetime.timedelta(hours=now.hour,\n",
    "                                                                minutes=now.minute, seconds=now.second,\n",
    "                                                               microseconds = now.microsecond)\n",
    "#     print(\"Current Date is :\\t\"+current_date.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "\n",
    "    # datetime.timedelta(days=1) ---> in order to get the previous date\n",
    "    # strftime ('%d-%m-%Y')  ---> To get the date in time desired format\n",
    "    date_folder_raw = current_date - datetime.timedelta(days=i)\n",
    "\n",
    "    date_folder = date_folder_raw.strftime('%d-%m-%Y')\n",
    "    print(\"folder name ---> \"+date_folder,end='\\n')\n",
    "\n",
    "    # Parent Directory path\n",
    "    parent_dir = \"/home/bluepi/Downloads/Update/product_info\"\n",
    "    # os.path.join --> join one or more path components\n",
    "    path = os.path.join(parent_dir, date_folder)\n",
    "\n",
    "    # Creating Directory\n",
    "    try:\n",
    "        os.mkdir(path)\n",
    "    except Exception:\n",
    "        if len(os.listdir(path)) == 0:\n",
    "            print(date_folder + \" --> directory already present and empty\")\n",
    "        else:\n",
    "            print(date_folder + \" --> directory already present and not empty\")\n",
    "            continue\n",
    "\n",
    "# *****************************************************************************************\n",
    "    limit = datetime.timedelta(hours=18)\n",
    "    day_hour_begin = datetime.timedelta(hours=3)\n",
    "    day_hour = datetime.timedelta(hours=3)\n",
    "\n",
    "# This for loop is to create files inside the folders\n",
    "# We are updating our product 4 times a day only\n",
    "    for j in range(4):\n",
    "\n",
    "        # This section is for updating existing products :-\n",
    "\n",
    "        # Since we want our day_hour variable to within a range of 24 hours\n",
    "        if day_hour > limit:\n",
    "            day_hour = datetime.timedelta(hours=3)\n",
    "        else:\n",
    "            # Since next file is created in an interval of 4 hours\n",
    "            day_hour += datetime.timedelta(hours=3) + day_hour_begin\n",
    "\n",
    "        # Generate random values\n",
    "        value = random.randint(1, 10)\n",
    "\n",
    "        # This is used to sample out random number of rows\n",
    "        data_random_subset = data.sample(n=value,replace=True)\n",
    "\n",
    "# We dont want our deleted products to be included in as a updated product\n",
    "#        print(\"deleted_product\",end = '\\n')\n",
    "#        print(deleted_product,end = '\\n')\n",
    "\n",
    "################################################################\n",
    "\n",
    "#        print(\"data_random_subset before deleting--->\")\n",
    "#        print(data_random_subset['p_id'].values,end='\\n')\n",
    "        for k in deleted_product:\n",
    "            if (k in data_random_subset['p_id'].values):\n",
    "                # Get names of indexes for which p_id has value equal to i\n",
    "                indexNames = data_random_subset[data_random_subset['p_id'] == k].index\n",
    "\n",
    "                # Print it\n",
    "#                print(data_random_subset[data_random_subset['p_id'] == k],end = ' ')\n",
    "\n",
    "                # Delete these row indexes from dataFrame\n",
    "                data_random_subset.drop(indexNames, inplace=True)\n",
    "\n",
    "#        print(\"\\n data_random_subset after deleting--->\")\n",
    "#        print(data_random_subset['p_id'].values,end='\\n')\n",
    "\n",
    "#################################################################\n",
    "\n",
    "        # Drop the \"existing or old price\" price column\n",
    "        data_random_subset = data_random_subset.drop(['price'],\n",
    "                                                     axis=1)\n",
    "\n",
    "        # Add new price column with new prices\n",
    "        # size --> size of array which we want\n",
    "        data_random_subset['price'] = np.random.randint(\n",
    "            1, 1500, size=data_random_subset.shape[0])\n",
    "\n",
    "        # To create date_timestamp\n",
    "        # here we used list comprehensions\n",
    "        # datetime.datetime.today() ---> get the today's date\n",
    "\n",
    "        # datetime.timedelta(minutes= ...,seconds=...) ---> used for calculating differences in dates & date manipulations\n",
    "        data_random_subset['date_timestamp'] = [\n",
    "            (date_folder_raw - datetime.timedelta(days=1) + day_hour +\n",
    "             datetime.timedelta(minutes=random.randint(10, 60),\n",
    "                                seconds=random.randint(\n",
    "                                    10, 100))).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            for i in range(data_random_subset.shape[0])\n",
    "        ]\n",
    "\n",
    "        # Adding record type data\n",
    "        data_random_subset['record_type'] = 'U'\n",
    "\n",
    "        # *****************************************************************************************\n",
    "\n",
    "# This section is for inserting New Products :-\n",
    "\n",
    "        # Generate random values\n",
    "        value_2 = random.randint(1, 4)\n",
    "\n",
    "        # new products picked at random\n",
    "        new_data_random_subset = new_product.sample(n=value_2,replace=True)\n",
    "#######################################################################################\n",
    "\n",
    "        # Updating new product file by removing already added products\n",
    "        new_product.drop(new_data_random_subset.index, inplace=True)\n",
    "        \n",
    "        \n",
    "########################################################################################\n",
    "\n",
    "        # Adding the date timestamp\n",
    "        new_data_random_subset['date_timestamp'] = [\n",
    "            (date_folder_raw - datetime.timedelta(days=1) + day_hour +\n",
    "             datetime.timedelta(minutes=random.randint(10, 60),\n",
    "                                seconds=random.randint(\n",
    "                                    10, 100))).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            for i in range(new_data_random_subset.shape[0])\n",
    "        ]\n",
    "\n",
    "        # Adding the record type\n",
    "        new_data_random_subset['record_type'] = 'I'\n",
    "\n",
    "        # Concating newly added and updated products\n",
    "        final_day_update = pd.concat(\n",
    "            [data_random_subset, new_data_random_subset], sort=False)\n",
    "        \n",
    "########################################################################################\n",
    "        \n",
    "        # Add this newly added products to product dataset\n",
    "        data = pd.concat([data, new_data_random_subset.loc[:,('p_id','p_name','price')]], sort=False)\n",
    "#         print(data['p_id'].count())\n",
    "        \n",
    "        data_pid.extend(new_data_random_subset['p_id'].tolist())\n",
    "#         print(\"\\t\"+str(len(data_pid)))\n",
    "        \n",
    "########################################################################################\n",
    "        \n",
    "\n",
    "        \n",
    "        # *****************************************************************************************\n",
    "\n",
    "# # This section is for Deleting the Products :-\n",
    "\n",
    "        # Picking up the pid from main table which we want to delete\n",
    "        to_be_deleted = random.choices(data_pid, k=random.randint(0, 4))\n",
    "\n",
    "#        print(\" to be deleted products--> \");print(to_be_deleted,end = '\\n')\n",
    "\n",
    "        # Check wheather the product is already deleted or not\n",
    "        for i in to_be_deleted:\n",
    "            # If pid is already deleted\n",
    "            if i in deleted_product:\n",
    "                # REMOVE IT.\n",
    "                to_be_deleted.remove(i)\n",
    "            else:\n",
    "                # If not append it to the deleted products list\n",
    "                deleted_product.append(i)\n",
    "\n",
    "# Creating a dataframe of the products which have to be deleted\n",
    "        deleted_that_day = data[data['p_id'].isin(to_be_deleted)]\n",
    "        # Drop the \"existing or old price\" price column\n",
    "        #deleted_that_day = deleted_that_day.drop(['day', 'time'], axis=1)\n",
    "\n",
    "        # Adding the date timestamp\n",
    "        deleted_that_day['date_timestamp'] = [\n",
    "            (date_folder_raw - datetime.timedelta(days=1) + day_hour +\n",
    "             datetime.timedelta(minutes=random.randint(10, 60),\n",
    "                                seconds=random.randint(\n",
    "                                    10, 100))).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            for i in range(deleted_that_day.shape[0])\n",
    "        ]\n",
    "\n",
    "        # Adding the record type\n",
    "        deleted_that_day['record_type'] = 'D'\n",
    "\n",
    "        # Concating newly added and updated products\n",
    "        final_final_day_update = pd.concat(\n",
    "            [final_day_update, deleted_that_day], sort=False)\n",
    "\n",
    "        # *****************************************************************************************\n",
    "\n",
    "        # Create the file name as it would be random\n",
    "        file_name = str(''.join(\n",
    "            random.choices(string.ascii_uppercase + string.digits, k=10)))\n",
    "        # File path\n",
    "        path_csv = path + '/' + file_name + '.csv'\n",
    "        # Exporting the csv file\n",
    "#        print('\\n\\n')\n",
    "        final_final_day_update.to_csv(path_csv, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-08T15:02:03.478514Z",
     "start_time": "2020-04-08T15:02:03.469925Z"
    },
    "run_control": {
     "marked": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[151, 151, 157, 149]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data_random_subset['p_id'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-08T15:02:03.499011Z",
     "start_time": "2020-04-08T15:02:03.480489Z"
    }
   },
   "outputs": [],
   "source": [
    "data_pid.extend([9999,99999,999999])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-08T15:02:03.522433Z",
     "start_time": "2020-04-08T15:02:03.504015Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 23,\n",
       " 24,\n",
       " 25,\n",
       " 26,\n",
       " 27,\n",
       " 28,\n",
       " 29,\n",
       " 30,\n",
       " 31,\n",
       " 32,\n",
       " 33,\n",
       " 34,\n",
       " 35,\n",
       " 36,\n",
       " 37,\n",
       " 38,\n",
       " 39,\n",
       " 40,\n",
       " 41,\n",
       " 42,\n",
       " 43,\n",
       " 44,\n",
       " 45,\n",
       " 46,\n",
       " 47,\n",
       " 48,\n",
       " 49,\n",
       " 50,\n",
       " 51,\n",
       " 52,\n",
       " 53,\n",
       " 54,\n",
       " 55,\n",
       " 56,\n",
       " 57,\n",
       " 58,\n",
       " 59,\n",
       " 60,\n",
       " 61,\n",
       " 62,\n",
       " 63,\n",
       " 64,\n",
       " 65,\n",
       " 66,\n",
       " 67,\n",
       " 68,\n",
       " 69,\n",
       " 70,\n",
       " 71,\n",
       " 72,\n",
       " 73,\n",
       " 74,\n",
       " 75,\n",
       " 76,\n",
       " 77,\n",
       " 78,\n",
       " 79,\n",
       " 80,\n",
       " 81,\n",
       " 82,\n",
       " 83,\n",
       " 84,\n",
       " 85,\n",
       " 86,\n",
       " 87,\n",
       " 88,\n",
       " 89,\n",
       " 90,\n",
       " 91,\n",
       " 92,\n",
       " 93,\n",
       " 94,\n",
       " 95,\n",
       " 96,\n",
       " 97,\n",
       " 98,\n",
       " 99,\n",
       " 100,\n",
       " 170,\n",
       " 134,\n",
       " 158,\n",
       " 191,\n",
       " 103,\n",
       " 184,\n",
       " 160,\n",
       " 192,\n",
       " 133,\n",
       " 131,\n",
       " 117,\n",
       " 109,\n",
       " 102,\n",
       " 196,\n",
       " 147,\n",
       " 155,\n",
       " 187,\n",
       " 152,\n",
       " 115,\n",
       " 127,\n",
       " 146,\n",
       " 137,\n",
       " 165,\n",
       " 188,\n",
       " 105,\n",
       " 119,\n",
       " 178,\n",
       " 190,\n",
       " 153,\n",
       " 126,\n",
       " 101,\n",
       " 120,\n",
       " 200,\n",
       " 116,\n",
       " 199,\n",
       " 130,\n",
       " 186,\n",
       " 121,\n",
       " 164,\n",
       " 128,\n",
       " 150,\n",
       " 167,\n",
       " 162,\n",
       " 162,\n",
       " 177,\n",
       " 144,\n",
       " 138,\n",
       " 136,\n",
       " 110,\n",
       " 132,\n",
       " 154,\n",
       " 106,\n",
       " 185,\n",
       " 159,\n",
       " 182,\n",
       " 148,\n",
       " 189,\n",
       " 139,\n",
       " 104,\n",
       " 141,\n",
       " 161,\n",
       " 122,\n",
       " 174,\n",
       " 171,\n",
       " 169,\n",
       " 108,\n",
       " 181,\n",
       " 107,\n",
       " 193,\n",
       " 129,\n",
       " 166,\n",
       " 168,\n",
       " 194,\n",
       " 183,\n",
       " 176,\n",
       " 123,\n",
       " 173,\n",
       " 179,\n",
       " 195,\n",
       " 124,\n",
       " 198,\n",
       " 180,\n",
       " 112,\n",
       " 111,\n",
       " 114,\n",
       " 125,\n",
       " 197,\n",
       " 197,\n",
       " 135,\n",
       " 172,\n",
       " 145,\n",
       " 142,\n",
       " 118,\n",
       " 140,\n",
       " 151,\n",
       " 151,\n",
       " 157,\n",
       " 149,\n",
       " 9999,\n",
       " 99999,\n",
       " 999999]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_pid\n"
   ]
  }
 ],
 "metadata": {
  "gist": {
   "data": {
    "description": "Documents/BluePi/Use Case/generate_data_script.ipynb",
    "public": true
   },
   "id": ""
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "480.5px",
    "left": "919px",
    "right": "20px",
    "top": "121px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
